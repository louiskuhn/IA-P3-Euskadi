# Veille sur les RNN

- Les RNN :
>- principe
>- représentation graphique
>- structures

- La fuite du gradient
>- c'est quoi le gradient et quel est son rôle en ML/DL ?
>- c'est quoi le problème du vanishing/exploding gradient ?
>- pourquoi le problème se pose dans les RNN et moins avec les autres réseaux ?
>- quelles solutions ?

- LSTM
>- principe
>- description des étapes
>- variantes

Quelques ressources mais y en plein d'autres !
https://www.youtube.com/watch?v=EL439RMv3Xc
https://www.youtube.com/watch?v=3xgYxrNyE54
http://proceedings.mlr.press/v28/pascanu13.pdf
https://colah.github.io/posts/2015-08-Understanding-LSTMs/
https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714
