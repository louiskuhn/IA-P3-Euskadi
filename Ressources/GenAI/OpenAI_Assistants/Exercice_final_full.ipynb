{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice Final OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire soi-même un assistant OpenAI\n",
    "Un assistant qui est à la fois capable :\n",
    "- D’aller chercher les top 3 news à propos d’un sujet, à partir d’une date max ou pas, sur [NewsAPI](https://newsapi.org/), puis les résumer et les renvoyer sous forme de JSON avec la date, titre et résumé de l’article.\n",
    "\n",
    "- D’aller chercher des informations sur la [certification Dev IA 2023](https://github.com/louiskuhn/IA-P3-Euskadi/blob/main/Ressources/GenAI/OpenAI_Assistants/reglement_specifique_full_dev_ia_2023.pdf) en réutilisant le vector_store de l’exercice.\n",
    "\n",
    "L’assistant doit être robuste aux injections de prompt et ne doit rien faire d’autre que les tâches ci-dessus. Il doit répondre en français et présenter le moins possible d’hallucinations.\n",
    "\n",
    "Puis faire une interface pour le tout, avec [panel](https://panel.holoviz.org/) ou [gradio](https://www.gradio.app/guides/quickstart) par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI, OpenAI\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des instructions de l'assistant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très important de bien définir l'entrée et la sortie du modèle, ainsi que tous les différents cas de figures\n",
    "\n",
    "Il n'est pas parfait, vous pouvez essayer de jouer avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version avec uniquement les news\n",
    "\n",
    "assistant_instructions = \"\"\"\n",
    "Your task is to get 3 news articles based on the topic given by the user.\\\n",
    "The user may or may not provide a starting date for the articles.\\\n",
    "Use the provided functions to answer the questions.\\\n",
    "The 3 news articles must be returned in json format with the following schema : \n",
    "\n",
    "{\n",
    "  \"status\": \"failed, or succeeded\"\n",
    "  \"answer\": \"empty string, or the error\"\n",
    "  \"articles\":\n",
    "  [\n",
    "    {\n",
    "      \"article_title\": \"Title of the article in one sentence\",\n",
    "      \"article_source\": \"Name of the source of the article\",\n",
    "      \"article_description\": \"Description of the article\",\n",
    "      \"article_link\": \"url link to the article\",\n",
    "      \"article_date\": \"date the article was published at\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If the user gives no topic, answer the error \"Je ne suis pas sûr d'avoir compris, donnez-moi un sujet\"\\\n",
    ", unless the getNewsArticles function returned a non-empty list of articles\n",
    "If there is no news about the topic, that is if the getNewsArticles function is called and it returns an empty list of articles\\\n",
    ", answer the error \"Je n'ai pas trouvé d'articles à propos de ce sujet\" \n",
    "If the user asks for something else than news, answer the error \"Je suis désolé, je ne peux que fournir des news\"\n",
    "For any of the three failed cases above, return nothing in the article and a failed status\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function_description = \"\"\"\n",
    "Given keywords or a phrase to query, this function gets the 3 most \\\n",
    "relevant news articles. If a starting date is given, it will get \\\n",
    "articles published between the starting date and the present date. \\\n",
    "Expects a list of articles in json format as a response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version avec news + questions certif\n",
    "\n",
    "assistant_instructions_full = \"\"\"\n",
    "You have 2 possible use cases : Either you answer questions about the certification delivered by Simplon,\n",
    "or you get 3 news articles based on the topic given by the user.\\\n",
    "The user may or may not provide a starting date for the articles.\\\n",
    "Use the provided functions and file search to answer the questions.\\\n",
    "\n",
    "First, you will determine if the user is asking for news articles about a topic, that we will call use case 1, \\\n",
    "or if he's asking for information about the certification delivered by Simplon, that we will call use case 2.\n",
    "Once this is done:\n",
    "For use case 1:\n",
    "The 3 news articles must be returned in json format with the following schema : \n",
    "\n",
    "{\n",
    "  \"status\": \"failed, or succeeded\",\n",
    "  \"answer\": \"empty string, or the error\",\n",
    "  \"articles\":\n",
    "  [\n",
    "    {\n",
    "      \"article_title\": \"Title of the article in one sentence\",\n",
    "      \"article_source\": \"Name of the source of the article\",\n",
    "      \"article_description\": \"Description of the article\",\n",
    "      \"article_link\": \"url link to the article\",\n",
    "      \"article_date\": \"date the article was published at\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If the user gives no topic, answer the error \"Je ne suis pas sûr d'avoir compris, donnez-moi un sujet\"\\\n",
    ", unless the getNewsArticles function returned a non-empty list of articles\n",
    "If there is no news about the topic, that is if the getNewsArticles function is called and it returns an empty list of articles\\\n",
    ", answer the error \"Je n'ai pas trouvé d'articles à propos de ce sujet\" \n",
    "If the user asks for something else than news, answer the error \"Je suis désolé, je ne peux que fournir des news\"\n",
    "For any of the three failed cases above, return nothing in the article and a failed status\n",
    "\n",
    "For use case 2 :\n",
    "Try to find relevant sources in your resources and only answer the question based on those sources.\n",
    "The response must be returned ONLY in json format with the following schema:\n",
    "{\n",
    "  \"status\": \"failed, or succeeded\",\n",
    "  \"answer\": \"the answer of the model in its entirety with citation numbers between brackets, or the error\",\n",
    "  \"citations\": {\n",
    "    citation number: \"citation file name\"\n",
    "  }\n",
    "  \n",
    "}\n",
    "If relevant sources to answer to the question asked could not be found in  your resources, or if you are not certain, answer the error \\\n",
    "\"Désolé, nous n'avons pas pu trouvé la réponse à votre question dans nos données\"\n",
    "For the error case described above, return a failed status and an empty citations list\n",
    "\n",
    "The response must absolutely and only be returned in the json format specified for both use cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de l'assistant et de sa fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important de bien définir la description de la fonction et ses paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version avec uniquement les news\n",
    "\n",
    "\n",
    "# assistant = client.beta.assistants.create(\n",
    "#   instructions=assistant_instructions,\n",
    "#   name=\"news_assistant\",\n",
    "#   model='gpt-3.5-turbo', #Replace with model deployment name\n",
    "#   tools=[{\n",
    "#       \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#       \"name\": \"getNewsArticles\",\n",
    "#       \"description\": function_description,\n",
    "#       \"parameters\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#           \"query\": {\"type\": \"string\", \"description\": \"Keywords or a phrase to query articles.\"},\n",
    "#           \"limit_date\": {\"type\": \"string\", \"description\": \"starting date for articles in ISO 8601 format.\"}\n",
    "#         },\n",
    "#         \"required\": [\"query\"]\n",
    "#       }\n",
    "#     }\n",
    "#   }],\n",
    "#   response_format={ \"type\": \"json_object\" }\n",
    "# )\n",
    "# print(assistant) # asst_Wfgt7Q88W9FOFNWqmVd69ZMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version avec news + questions certif\n",
    "\n",
    "\n",
    "# assistant = client.beta.assistants.create(\n",
    "#   instructions=assistant_instructions,\n",
    "#   name=\"news_and_certification_assistant\",\n",
    "#   model='gpt-3.5-turbo', #Replace with model deployment name\n",
    "#   tools=[{\n",
    "#       \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#       \"name\": \"getNewsArticles\",\n",
    "#       \"description\": function_description,\n",
    "#       \"parameters\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#           \"query\": {\"type\": \"string\", \"description\": \"Keywords or a phrase to query articles.\"},\n",
    "#           \"limit_date\": {\"type\": \"string\", \"description\": \"starting date for articles in ISO 8601 format.\"}\n",
    "#         },\n",
    "#         \"required\": [\"query\"]\n",
    "#       }\n",
    "#     }\n",
    "#   },\n",
    "#   {\"type\": \"file_search\"}],\n",
    "#   tool_resources={\n",
    "#     \"file_search\": {\n",
    "#       \"vector_store_ids\": [\"vs_vUsPdfeq1ymnt0mC3BuU39Bq\"]\n",
    "#     }\n",
    "#   }\n",
    "# )\n",
    "# print(assistant) # asst_jbpMGP39cEMyhm6eD8JKO02r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour créer un thread et lui ajouter le prompt initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_and_message(message_content):\n",
    "  thread = client.beta.threads.create()\n",
    "  print(thread) # thread_xw9ufX67vrbyZljmRnfxuc3f\n",
    "\n",
    "  # Add a user question to the thread\n",
    "  message = client.beta.threads.messages.create(\n",
    "      thread_id=thread.id,\n",
    "      role=\"user\",\n",
    "      content=message_content\n",
    "  )\n",
    "  return thread\n",
    "# thread = create_thread_and_message(\"give me news about the olympic games in France from the last 3 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'appel d'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.parse\n",
    "\n",
    "news_api_key = os.getenv(\"NEWSAPI_API_KEY\")\n",
    "\n",
    "def getNewsArticles(**args):\n",
    "  try:\n",
    "    query = args.get('query')\n",
    "    limit_date = args.get('limit_date')\n",
    "    print(query)\n",
    "    print(limit_date)      \n",
    "    \n",
    "    url = 'https://newsapi.org/v2/everything'\n",
    "    params = {\n",
    "        'q': urllib.parse.quote(query),\n",
    "        'apiKey': news_api_key,\n",
    "        'sortBy': 'popularity',\n",
    "        'pageSize': 3,\n",
    "        'language': 'fr'\n",
    "    }\n",
    "    if limit_date:\n",
    "      today_date = date.today().strftime(format=\"%Y-%m-%d\")\n",
    "\n",
    "      if limit_date == today_date: # because the API doesn't work correctly with today's date as limit date\n",
    "        limit_date = datetime.strptime(limit_date, \"%Y-%m-%d\") - timedelta(days=1)\n",
    "        limit_date = limit_date.strftime(format=\"%Y-%m-%d\")\n",
    "\n",
    "      params['from'] = limit_date\n",
    "        \n",
    "\n",
    "    headers = {\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      article_data = data.get('articles')\n",
    "      print(article_data)\n",
    "      \n",
    "      return json.dumps(article_data)\n",
    "    else:\n",
    "        error_message = f\"Failed to retrieve data from API : {response.status_code}\"\n",
    "        error_dict = {\"status\": error_message}\n",
    "        return json.dumps(error_dict)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return '{\"status\": \"failed API Call\"}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments = json.loads('{\\\"query\\\":\\\"elections americaines\\\",\\\"limit_date\\\":\\\"2024-09-23\"}')\n",
    "# news = getNewsArticles(**arguments)\n",
    "# print(json.dumps(json.loads(news), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction répondant à tous les tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_function_outputs(run, thread):\n",
    "  if run.required_action.submit_tool_outputs.tool_calls:\n",
    "    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "    \n",
    "    tool_outputs = []\n",
    "    for i, tool_call in enumerate(tool_calls):\n",
    "      function_name = tool_call.function.name\n",
    "      arguments = json.loads(tool_call.function.arguments)\n",
    "      response = globals()[function_name](**arguments)\n",
    "\n",
    "      tool_outputs.append({\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"output\": response # doit contenir la réponse de votre fonction python qui prend en entrée les arguments renvoyés par le run\n",
    "      })\n",
    "\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "  return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction regroupant tout, pour permettre de tester un prompt en une seule ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def test_assistant(assistant_id, message_content):\n",
    "\n",
    "\n",
    "  thread = create_thread_and_message(message_content)\n",
    "\n",
    "  today_date = date.today().strftime(format=\"%Y-%m-%d\")\n",
    "\n",
    "  assistant = client.beta.assistants.update(\n",
    "    assistant_id,\n",
    "    instructions=assistant_instructions_full + f\" Today's date in ISO 8601 format is {today_date}.\"\n",
    "  )                                         \n",
    "\n",
    "  run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "  )\n",
    "\n",
    "  start_time = time.time()\n",
    "\n",
    "  status = run.status\n",
    "\n",
    "  while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\", \"incomplete\"]:\n",
    "    \n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = run.status\n",
    "    print(f'Status: {status}')\n",
    "\n",
    "    if run.status == \"requires_action\":\n",
    "      print('executing tools...')\n",
    "      run = submit_function_outputs(run, thread)\n",
    "      status = run.status\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "  if status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(\n",
    "      thread_id=thread.id\n",
    "    )\n",
    "    # clear_output(wait=True)\n",
    "    print(f'Status: {status}')\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "\n",
    "    model_response = messages.data[0].content[0].text.value\n",
    "\n",
    "\n",
    "    model_response = model_response.strip('` \\n')\n",
    "    if model_response.startswith('json'):\n",
    "        model_response = model_response[4:]\n",
    "\n",
    "    citations = []\n",
    "    if getattr(messages.data[0].content[0].text, 'annotations'):\n",
    "      annotations = messages.data[0].content[0].text.annotations\n",
    "      \n",
    "      for index, annotation in enumerate(annotations):\n",
    "        model_response = model_response.replace(annotation.text, f\"[{index}]\")\n",
    "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "          cited_file = client.files.retrieve(file_citation.file_id)\n",
    "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "    try:\n",
    "      print(json.dumps(json.loads(model_response), indent=2).encode('utf-8').decode('unicode_escape'))\n",
    "    except:\n",
    "      print(\"couldn't print json response\")\n",
    "      print(model_response)\n",
    "    \n",
    "    if citations:\n",
    "      print(citations)\n",
    "      \n",
    "\n",
    "\n",
    "  else:\n",
    "    if getattr(run, 'last_error'):\n",
    "      print(f\"Last error: {run.last_error}\")\n",
    "    if getattr(run, 'incomplete_details'):\n",
    "      print(run.incomplete_details)\n",
    "    print(f\"Assistant status: {status}\")\n",
    "  \n",
    "  \n",
    "  \n",
    "      \n",
    "  return messages\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://aa40ed31093925c65a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://aa40ed31093925c65a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_vbZJk8Qrvao0kYxVbOY0XeBl', created_at=1727677993, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Status: completed\n",
      "Elapsed time before function call: 0 minutes 11 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time total: 0 minutes 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\chat_interface.py\", line 652, in _stream_fn\n",
      "    first_response = await async_iteration(generator)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 663, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 656, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 642, in run_sync_iterator_async\n",
      "    raise StopAsyncIteration() from None\n",
      "StopAsyncIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\blocks.py\", line 1923, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 663, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 768, in asyncgen_wrapper\n",
      "    response = await iterator.__anext__()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: async generator raised StopAsyncIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_CstW5lGOS8DPkzZvmC2G1vqQ', created_at=1727678046, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Status: completed\n",
      "Elapsed time before function call: 0 minutes 9 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time total: 0 minutes 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\chat_interface.py\", line 652, in _stream_fn\n",
      "    first_response = await async_iteration(generator)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 663, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 656, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 642, in run_sync_iterator_async\n",
      "    raise StopAsyncIteration() from None\n",
      "StopAsyncIteration\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\blocks.py\", line 1923, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 663, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luca5\\.conda\\envs\\GENAI\\Lib\\site-packages\\gradio\\utils.py\", line 768, in asyncgen_wrapper\n",
      "    response = await iterator.__anext__()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: async generator raised StopAsyncIteration\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "def run_assistant_chatbot(message, history,\n",
    "                          request: gr.Request,\n",
    "                          assistant_id=\"asst_zgsWyBwKdWenyzpi9hGEl5h6\"):\n",
    "    \n",
    "  session_thread = create_thread_and_message(message)\n",
    "\n",
    "  today_date = date.today().strftime(format=\"%Y-%m-%d\")\n",
    "\n",
    "  assistant = client.beta.assistants.update(\n",
    "    assistant_id,\n",
    "    instructions=assistant_instructions_full + f\"Today's date in ISO 8601 format is {today_date}.\"\n",
    "  )\n",
    "\n",
    "  start_time = time.time()\n",
    "  run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=session_thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "  )\n",
    "\n",
    "  print(f'Status: {run.status}')\n",
    "  print(\"Elapsed time before function call: {} minutes {} seconds\"\n",
    "        .format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "\n",
    "\n",
    "  if run.status == \"requires_action\":\n",
    "    print('executing tools...')\n",
    "    run = submit_function_outputs(run, session_thread)\n",
    "    print(\"Elapsed time after function call: {} minutes {} seconds\"\n",
    "        .format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "  # for debugging\n",
    "  else:\n",
    "    if getattr(run, 'last_error'):\n",
    "      print(f\"Last error: {run.last_error}\")\n",
    "    if getattr(run, 'incomplete_details'):\n",
    "      print(run.incomplete_details)\n",
    "    print(f'Status: {run.status}')\n",
    "\n",
    "  if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(\n",
    "      thread_id=session_thread.id\n",
    "    )\n",
    "\n",
    "    print(f'Status: {run.status}')\n",
    "    print(\"Elapsed time total: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "\n",
    "    model_response = messages.data[0].content[0].text.value\n",
    "\n",
    "    # Comme on a une réponse en JSON, on peut l'analyser pour modifier la réponse envoyée à l'utilisateur.\n",
    "\n",
    "    try:\n",
    "      json_model_response = json.loads(model_response)\n",
    "      if json_model_response.get('status') == 'failed':\n",
    "        return json_model_response.get('answer')\n",
    "      else:\n",
    "        articles = json.dumps(json_model_response.get('articles'), indent=2).encode('utf-8').decode('unicode_escape')\n",
    "        for index in range(len(articles)):\n",
    "          time.sleep(0.01)\n",
    "          yield articles[0:index+1]\n",
    "    except Exception as e:\n",
    "      return \"could not read model response\"\n",
    "    \n",
    "\n",
    "  else:\n",
    "    if getattr(run, 'last_error'):\n",
    "      print(f\"Last error: {run.last_error}\")\n",
    "    if getattr(run, 'incomplete_details'):\n",
    "      print(run.incomplete_details)\n",
    "    return f\"Run status: {run.status}\"\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    run_assistant_chatbot,\n",
    "    chatbot=gr.Chatbot(height=400),\n",
    "    textbox=gr.Textbox(placeholder=\"Votre question ici\", container=False, scale=7),\n",
    "    title=\"Le bot de la certification développeur IA mais aussi des news\",\n",
    "    description=\"Pose moi des questions sur ta certification ou sur les nouvelles que tu souhaites\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"Quel est le programme de la certification IA 2023?\", \"Quelles sont les news sur l'IA cette semaine?\"],\n",
    "    cache_examples=False,\n",
    "    retry_btn=None,\n",
    "    undo_btn=None,\n",
    "    clear_btn=None,\n",
    ").launch(share=True) # share=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayez vous même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore(id='vs_lrYKplXCKWpkkgtXUXzeanNt', created_at=1722355697, file_counts=FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1), last_active_at=1727676926, metadata={}, name='Certif 5 Pages IA 2023', object='vector_store', status='completed', usage_bytes=23160, expires_after=None, expires_at=None)\n",
      "vector store already exists\n"
     ]
    }
   ],
   "source": [
    "# bout de code pour éviter de créer plein de fois le même vector store\n",
    "try : \n",
    "  vector_store = client.beta.vector_stores.retrieve(\n",
    "    vector_store_id=\"vs_lrYKplXCKWpkkgtXUXzeanNt\"\n",
    "  )\n",
    "  print(vector_store)\n",
    "  print(\"vector store already exists\")\n",
    "\n",
    "except Exception as e:\n",
    "  print(\"vector store not found\")\n",
    "\n",
    "  # Create a vector store caled \"Certif 5 Pages IA 2023\"\n",
    "  vector_store = client.beta.vector_stores.create(name=\"Certif 5 Pages IA 2023\")\n",
    "  \n",
    "  # Ready the files for upload to OpenAI\n",
    "  file_paths = [\"reglement_specifique_5_pages_dev_ia_2023.pdf\"]\n",
    "  file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "  \n",
    "  # Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "  # and poll the status of the file batch for completion.\n",
    "  file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    "  )\n",
    "  \n",
    "  # You can print the status and the file counts of the batch to see the result of this operation.\n",
    "  print(file_batch.model_dump_json(indent=2))\n",
    "  print(file_batch.status)\n",
    "  print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs_lrYKplXCKWpkkgtXUXzeanNt (5 pages) ou vs_1Hgcfus8FuqgRINpJq7iAkfG (full)\n",
    "\n",
    "assistant = client.beta.assistants.update(\n",
    "  \"asst_zgsWyBwKdWenyzpi9hGEl5h6\",\n",
    "  temperature=0.2,\n",
    "  tool_resources={\n",
    "  \"file_search\": {\n",
    "    \"vector_store_ids\": [\"vs_lrYKplXCKWpkkgtXUXzeanNt\"]\n",
    "  }\n",
    "  }\n",
    ")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_bDEbJR9ul2OmYUD7nIO0vbB6', created_at=1727340757, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Elapsed time: 0 minutes 0 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 2 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 5 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 7 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time: 0 minutes 10 seconds\n",
      "{\n",
      "  \"status\": \"succeeded\",\n",
      "  \"answer\": \"Le jury de la certification est composé de professionnels du secteur et de formateurs habilités. Ils sont responsables de l'évaluation des compétences des candidats à travers des épreuves certificatives, des cas pratiques, des mises en situation professionnelle, et des soutenances orales[0].\",\n",
      "  \"citations\": {\n",
      "    \"0\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\"\n",
      "  }\n",
      "}\n",
      "['[0] reglement_specifique_5_pages_dev_ia_2023.pdf']\n",
      "SyncCursorPage[Message](data=[Message(id='msg_poc2e5hyuVM439miEnFF8Az8', assistant_id='asst_zgsWyBwKdWenyzpi9hGEl5h6', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=340, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=328, text='【6:0†source】', type='file_citation')], value='{\\n  \"status\": \"succeeded\",\\n  \"answer\": \"Le jury de la certification est composé de professionnels du secteur et de formateurs habilités. Ils sont responsables de l\\'évaluation des compétences des candidats à travers des épreuves certificatives, des cas pratiques, des mises en situation professionnelle, et des soutenances orales【6:0†source】.\",\\n  \"citations\": {\\n    \"0\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\"\\n  }\\n}'), type='text')], created_at=1727340763, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_8cZXTJ3R0omPo1hD2FXwaHkF', status=None, thread_id='thread_bDEbJR9ul2OmYUD7nIO0vbB6'), Message(id='msg_PsGqyFJMxl3JX2fZMmv1VDdg', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Quelle est la composition exacte du jury de la certification?'), type='text')], created_at=1727340757, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_bDEbJR9ul2OmYUD7nIO0vbB6')], object='list', first_id='msg_poc2e5hyuVM439miEnFF8Az8', last_id='msg_PsGqyFJMxl3JX2fZMmv1VDdg', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# asst_jbpMGP39cEMyhm6eD8JKO02r ou asst_zgsWyBwKdWenyzpi9hGEl5h6 (gpt-4o)\n",
    "\n",
    "prompt = \"Quelle est la composition exacte du jury de la certification?\"\n",
    "messages = test_assistant('asst_zgsWyBwKdWenyzpi9hGEl5h6', prompt)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_JOuaz3T5k0LDCbP64dZNlXcN', created_at=1722360551, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Elapsed time: 0 minutes 0 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 2 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 4 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 6 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time: 0 minutes 9 seconds\n",
      "{\n",
      "  \"status\": \"failed\",\n",
      "  \"answer\": \"Désolé, nous n'avons pas pu trouvé la réponse à votre question dans nos données\",\n",
      "  \"citations\": {}\n",
      "}\n",
      "SyncCursorPage[Message](data=[Message(id='msg_buzreg1RBiEcMXuhcilkIYeY', assistant_id='asst_zgsWyBwKdWenyzpi9hGEl5h6', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n  \"status\": \"failed\",\\n  \"answer\": \"Désolé, nous n\\'avons pas pu trouvé la réponse à votre question dans nos données\",\\n  \"citations\": {}\\n}\\n```'), type='text')], created_at=1722360557, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_fF3nxaJl4DsNCUkzUkIK0VwW', status=None, thread_id='thread_JOuaz3T5k0LDCbP64dZNlXcN'), Message(id='msg_ScD1jt1L0C9S5oN0jrry5M5E', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Fais-moi un résumé du risque encouru en cas de fraude'), type='text')], created_at=1722360551, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_JOuaz3T5k0LDCbP64dZNlXcN')], object='list', first_id='msg_buzreg1RBiEcMXuhcilkIYeY', last_id='msg_ScD1jt1L0C9S5oN0jrry5M5E', has_more=False)\n",
      "Thread(id='thread_DYwi37qNg4bGhgCM91Dp0mO5', created_at=1722364583, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Elapsed time: 0 minutes 0 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 2 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 4 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 6 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 9 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 11 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time: 0 minutes 13 seconds\n",
      "{\n",
      "  \"status\": \"succeeded\",\n",
      "  \"answer\": \"En cas de fraude, les risques encourus peuvent être multiples et sévères. Les sanctions peuvent inclure des peines d'emprisonnement, des amendes substantielles, ainsi que des interdictions d'exercer certaines professions. Les conséquences peuvent également s'étendre à des dommages à la réputation, des pertes financières, et des poursuites civiles. Les sanctions spécifiques dépendent de la nature et de la gravité de la fraude commise[0][1][2].\",\n",
      "  \"citations\": {\n",
      "    \"1\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\",\n",
      "    \"2\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\",\n",
      "    \"3\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\"\n",
      "  }\n",
      "}\n",
      "['[0] reglement_specifique_5_pages_dev_ia_2023.pdf', '[1] reglement_specifique_5_pages_dev_ia_2023.pdf', '[2] reglement_specifique_5_pages_dev_ia_2023.pdf']\n",
      "SyncCursorPage[Message](data=[Message(id='msg_MjeEWUk2eSsgFYrTKd1Vk8Fi', assistant_id='asst_zgsWyBwKdWenyzpi9hGEl5h6', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=496, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=484, text='【4:0†source】', type='file_citation'), FileCitationAnnotation(end_index=508, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=496, text='【6:1†source】', type='file_citation'), FileCitationAnnotation(end_index=520, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=508, text='【8:2†source】', type='file_citation')], value='```json\\n{\\n  \"status\": \"succeeded\",\\n  \"answer\": \"En cas de fraude, les risques encourus peuvent être multiples et sévères. Les sanctions peuvent inclure des peines d\\'emprisonnement, des amendes substantielles, ainsi que des interdictions d\\'exercer certaines professions. Les conséquences peuvent également s\\'étendre à des dommages à la réputation, des pertes financières, et des poursuites civiles. Les sanctions spécifiques dépendent de la nature et de la gravité de la fraude commise【4:0†source】【6:1†source】【8:2†source】.\",\\n  \"citations\": {\\n    \"1\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\",\\n    \"2\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\",\\n    \"3\": \"file-JRnXaDrYTLCqbQnOb8DtJryF\"\\n  }\\n}\\n```'), type='text')], created_at=1722364591, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_scTlJge83XQ2fx9TmwVypfTA', status=None, thread_id='thread_DYwi37qNg4bGhgCM91Dp0mO5'), Message(id='msg_inQmo8vJas7ywcccBiTXERMX', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Fais-moi un résumé du risque encouru en cas de fraude'), type='text')], created_at=1722364583, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_DYwi37qNg4bGhgCM91Dp0mO5')], object='list', first_id='msg_MjeEWUk2eSsgFYrTKd1Vk8Fi', last_id='msg_inQmo8vJas7ywcccBiTXERMX', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# asst_jbpMGP39cEMyhm6eD8JKO02r ou asst_zgsWyBwKdWenyzpi9hGEl5h6 (gpt-4o)\n",
    "for i in range(10):\n",
    "  prompt = \"Fais-moi un résumé du risque encouru en cas de fraude\"\n",
    "  messages = test_assistant('asst_zgsWyBwKdWenyzpi9hGEl5h6', prompt)\n",
    "  print(messages)\n",
    "  time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_R7wyJzQaBKE4ecobRQH4ywvw', created_at=1722358114, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Elapsed time: 0 minutes 0 seconds\n",
      "Status: queued\n",
      "Elapsed time: 0 minutes 2 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 4 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time: 0 minutes 6 seconds\n",
      "{\n",
      "  \"status\": \"failed\",\n",
      "  \"answer\": \"Je suis désolé, je ne peux que fournir des news\",\n",
      "  \"articles\": []\n",
      "}\n",
      "SyncCursorPage[Message](data=[Message(id='msg_tjp8zTHoaz6zJoieXRtM7iV0', assistant_id='asst_zgsWyBwKdWenyzpi9hGEl5h6', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='```json\\n{\\n  \"status\": \"failed\",\\n  \"answer\": \"Je suis désolé, je ne peux que fournir des news\",\\n  \"articles\": []\\n}\\n```'), type='text')], created_at=1722358119, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_Wdpy4bfn8gQsrLqBgf6CMWL4', status=None, thread_id='thread_R7wyJzQaBKE4ecobRQH4ywvw'), Message(id='msg_WqkGAiiP8Y8BXN51C439droW', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Who is Donald Trump?'), type='text')], created_at=1722358115, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_R7wyJzQaBKE4ecobRQH4ywvw')], object='list', first_id='msg_tjp8zTHoaz6zJoieXRtM7iV0', last_id='msg_WqkGAiiP8Y8BXN51C439droW', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Who is Donald Trump?\"\n",
    "messages = test_assistant('asst_zgsWyBwKdWenyzpi9hGEl5h6', prompt)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_2718sDQYDkW3zWzuRxmbc5SF', created_at=1727678464, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "Elapsed time: 0 minutes 0 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 2 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 4 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 6 seconds\n",
      "Status: in_progress\n",
      "Elapsed time: 0 minutes 9 seconds\n",
      "Status: completed\n",
      "Status: completed\n",
      "Elapsed time: 0 minutes 11 seconds\n",
      "{\n",
      "  \"status\": \"succeeded\",\n",
      "  \"answer\": \"Pour le bloc de compétences 1 de la certification Simplon, les éléments de preuves attendus incluent :\n",
      "\n",
      "1. **Automatisation de l'extraction de données** : Automatiser l’extraction de données depuis un service web, une page web (scraping), un fichier de données, une base de données et un système big data en programmant le script adapté afin de pérenniser la collecte des données nécessaires au projet[0].\n",
      "\n",
      "2. **Développement de requêtes SQL** : Développer des requêtes de type SQL d’extraction des données depuis un système de gestion de base de données et un système big data en appliquant le langage de requête propre au système afin de préparer la collecte des données nécessaires au projet[0].\n",
      "\n",
      "3. **Création d'une base de données respectant le RGPD** : Créer une base de données dans le respect du RGPD en élaborant les modèles conceptuels et physiques des données à partir des données préparées et en programmant leur import afin de stocker le jeu de données du projet[0].\",\n",
      "  \"citations\": {\n",
      "    \"1\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\",\n",
      "    \"2\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\",\n",
      "    \"3\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\"\n",
      "  }\n",
      "}\n",
      "['[0] reglement_specifique_5_pages_dev_ia_2023.pdf', '[1] reglement_specifique_5_pages_dev_ia_2023.pdf', '[2] reglement_specifique_5_pages_dev_ia_2023.pdf']\n",
      "SyncCursorPage[Message](data=[Message(id='msg_rMLrUVP8WqZk5G5fvHKDYAkF', assistant_id='asst_zgsWyBwKdWenyzpi9hGEl5h6', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=455, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=443, text='【4:1†source】', type='file_citation'), FileCitationAnnotation(end_index=759, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=747, text='【4:1†source】', type='file_citation'), FileCitationAnnotation(end_index=1051, file_citation=FileCitation(file_id='file-JRnXaDrYTLCqbQnOb8DtJryF', quote=None), start_index=1039, text='【4:1†source】', type='file_citation')], value='{\\n  \"status\": \"succeeded\",\\n  \"answer\": \"Pour le bloc de compétences 1 de la certification Simplon, les éléments de preuves attendus incluent :\\\\n\\\\n1. **Automatisation de l\\'extraction de données** : Automatiser l’extraction de données depuis un service web, une page web (scraping), un fichier de données, une base de données et un système big data en programmant le script adapté afin de pérenniser la collecte des données nécessaires au projet【4:1†source】.\\\\n\\\\n2. **Développement de requêtes SQL** : Développer des requêtes de type SQL d’extraction des données depuis un système de gestion de base de données et un système big data en appliquant le langage de requête propre au système afin de préparer la collecte des données nécessaires au projet【4:1†source】.\\\\n\\\\n3. **Création d\\'une base de données respectant le RGPD** : Créer une base de données dans le respect du RGPD en élaborant les modèles conceptuels et physiques des données à partir des données préparées et en programmant leur import afin de stocker le jeu de données du projet【4:1†source】.\",\\n  \"citations\": {\\n    \"1\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\",\\n    \"2\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\",\\n    \"3\": \"reglement_specifique_5_pages_dev_ia_2023.pdf\"\\n  }\\n}'), type='text')], created_at=1727678468, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_PEijaXagQ4BQuNsWgrgn9AID', status=None, thread_id='thread_2718sDQYDkW3zWzuRxmbc5SF'), Message(id='msg_rlVerwraLFSeuUda0CTSx1Ei', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Quels sont les éléments de preuves attendus pour le bloc de compétences 1? Donne 3 exemples'), type='text')], created_at=1727678464, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_2718sDQYDkW3zWzuRxmbc5SF')], object='list', first_id='msg_rMLrUVP8WqZk5G5fvHKDYAkF', last_id='msg_rlVerwraLFSeuUda0CTSx1Ei', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Quels sont les éléments de preuves attendus pour le bloc de compétences 1? Donne 3 exemples\"\n",
    "messages = test_assistant('asst_zgsWyBwKdWenyzpi9hGEl5h6', prompt)\n",
    "print(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GENAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
