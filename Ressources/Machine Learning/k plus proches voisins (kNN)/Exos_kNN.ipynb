{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les k-plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'algorithme kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les données puis on cherche à prédire la valeur $y^{(0)}$ pour l'observation $x^{(0)} = (x^{(0)}_i)_{i \\in [1,p]}$.  \n",
    "Dans le cas de la classification, cela revient à avoir un $y^{(0)}$ catégorique où les modalités sont les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. Initialiser $k$ et choisir une fonction de distance\n",
    ">2. Pour chaque observation $x^{(i)}$ dans les données:\n",
    ">>a. Calculer la distance $d$ entre $x^{(0)}$ et $x^{(i)}$  \n",
    ">>b. Stocker la distance $d$ et l’indice $i$ de l’observation $x^{(i)}$ (dans une liste de couples par exemple)\n",
    ">4. Trier la liste contenant distances et indices de la plus petite distance à la plus grande (dans ordre croissant).\n",
    ">5. Sélectionner les $k$ premiers éléments\n",
    ">6. Obtenir les étiquettes des $k$ entrées sélectionnées\n",
    ">7. Si **régression**, retourner la moyenne des $k$ valeurs $y^{(i)}$ ; si **classification**, retourner le mode des $k$ classes $y^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémenter l'algorithme des k plus proches voisins dans le cas univarié. Tester cet algorithme sur les données ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données de régression\n",
    "# Colonne 0: taille (cm)\n",
    "# Colonne 1: poids (kg)\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "reg_data = np.array([\n",
    "    [167. ,  50.8],\n",
    "    [181.7,  61.4],\n",
    "    [176.3,  68.9],\n",
    "    [173.3,  64.1],\n",
    "    [172.2,  64.9],\n",
    "    [174.5,  55.5],\n",
    "    [177.3,  63.7],\n",
    "    [177.8,  61.4],\n",
    "    [172.5,  50.6],\n",
    "    [168.9,  57.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données de Classification\n",
    "# Colonne 0: age\n",
    "# Colonne 1: aime l'ananas dans la pizza\n",
    "\n",
    "import numpy as np\n",
    "clf_data = np.array([\n",
    "   [22, 1],\n",
    "   [23, 1],\n",
    "   [21, 1],\n",
    "   [18, 1],\n",
    "   [19, 1],\n",
    "   [25, 0],\n",
    "   [27, 0],\n",
    "   [29, 0],\n",
    "   [31, 0],\n",
    "   [45, 0],\n",
    "   [23, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Généraliser à des données multivariées et tester sur le dataset iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 1936, Edgar Anderson a collecté des données sur 3 espèces d'iris : \"iris setosa\", \"iris virginica\" et \"iris versicolor\"\n",
    "\n",
    "<img src=\"iris_setosa.jpeg\"><img src=\"iris_virginica.jpeg\"><img src=\"iris_versicolor.jpeg\">\n",
    "\n",
    "Pour chaque iris étudié, Anderson a mesuré (en cm) :\n",
    "- la largeur des sépales\n",
    "- la longueur des sépales\n",
    "- la largeur des pétales\n",
    "- la longueur des pétales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesurer le score du modèle pour un k donné (en utilisant un jeu de données test) puis comparer ce score pour différents k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser votre algorithme des kNN pour effectuer des recommendations de films : pour un film donné, l'algorithme doit renvoyer les 5 films les plus \"proches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "films = pd.read_csv('Movie-Ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant que vous l'avez bien compris, implémenté, testé et validé, vous pouvez chercher les implémentations existantes de cet algorithme dans Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
