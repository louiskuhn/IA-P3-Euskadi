{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this the t\n"
     ]
    }
   ],
   "source": [
    "file = open('test.txt', 'r')\n",
    "# print(type(file))\n",
    "print(file.read(10)) # read() lis tout, read(10) lis les 10 premiers caractères\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with ... as ... nous permet d'ouvrir notre fichier que dans le contexte du with et plus après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this the the 1st line\\n', 'and the 2nd\\n', 'and 3rd']\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt', 'r') as file: \n",
    "    print(file.readlines()) # renvois une liste des lignes\n",
    "    # print(file.readline()) # renvoie une ligne par une ligne\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'a') as file: # a pour append, ajouter à la fin\n",
    "    file.writelines(['test', 'test2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To read and write :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this the the 1st line\\n', 'and the 2nd\\n', 'and 3rd']\n",
      "<class 'list'>\n",
      "this the the 1st line\n",
      "\n",
      "and the 2nd\n",
      "\n",
      "and 3rd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\", \"r+\") as file:\n",
    "    data = file.readlines()\n",
    "    print(data)\n",
    "    print(type(data))\n",
    "\n",
    "    new_data = []\n",
    "    for line in data:\n",
    "        print(line)\n",
    "        new_data.append(line+\"new\")\n",
    "    \n",
    "    file.seek(0) # retourner au début, a la position 0\n",
    "    file.writelines(new_data) # puis écrire nos nouvelles lignes (attention ca va écrire par dessus ce qui existe déjà)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'department', 'birthday month']\n",
      "Column names are name, department, birthday month\n",
      "['John Smith', 'Accounting', 'November']\n",
      "November\n",
      "['Erica Meyers', 'IT', 'March']\n",
      "March\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_birthday.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader: # chaque row sera une liste avec les infos\n",
    "        print(row)\n",
    "        if line_count == 0:\n",
    "            headers = row\n",
    "            # join() pour joindre les éléments d'une liste bout à bout dans une string\n",
    "            print(f'Column names are {\", \".join(row)}') # ici avec \", \" entre chaque élément\n",
    "        else:\n",
    "            print(row[2]) # on accède à chaque élément avec son indice puisque c'est une liste\n",
    "\n",
    "        line_count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DictReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on pourra accéder à chaque élément de row avec leur key, puisque c'est un dictionnaire et non plus une liste.\n",
    "\n",
    "Il va automatiquement détecter la première ligne comme étant les noms des colonnes et donc les clés à utiliser pour chacune des valeurs des rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 2 lines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'John Smith': {'name': 'John Smith',\n",
       "  'department': 'Accounting',\n",
       "  'birthday month': 'November'},\n",
       " 'Erica Meyers': {'name': 'Erica Meyers',\n",
       "  'department': 'IT',\n",
       "  'birthday month': 'March'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "employees_info = {}\n",
    "with open('employee_birthday.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        print(f'\\t{row[\"name\"]} works in the {row[\"department\"]} department, and was born in {row[\"birthday month\"]}.')\n",
    "\n",
    "        employees_info[row['name']] = row\n",
    "\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n",
    "employees_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la fin on a un dictionnaire avec comme clés des identifiants (ici leur nom mais idéalement ce serait un identifiant dont on est sûrs qu'il est unique), et comme valeurs toutes leurs informations, elles-mêmes sous forme de dictionnaires. \n",
    "\n",
    "On a donc un dictionnaire de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'March'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees_info['Erica Meyers']['birthday month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employee_file.csv', mode='w') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, lineterminator='\\n', delimiter=';')\n",
    "\n",
    "    employee_writer.writerow([\"John Doe\" , \"IT\", 'July'])\n",
    "    employee_writer.writerow([\"John Doe2\" , \"IT\", 'July'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DictWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_file2.csv', mode='a') as csv_file:\n",
    "    fieldnames = ['emp_name', 'dept', 'birth_month']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'emp_name': 'John Smith', 'dept': 'Accounting', 'birth_month': 'November'})\n",
    "    writer.writerow({'emp_name': 'Erica Meyers', 'dept': 'IT', 'birth_month': 'March'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Omkar': {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000},\n",
       " 'Jagdish': {'key': 'Jagdish',\n",
       "  'name': 'Jagdish Pathak',\n",
       "  'age': 50,\n",
       "  'pay': 50000}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# initializing data to be stored in db\n",
    "Omkar = {'key' : 'Omkar', 'name' : 'Omkar Pathak',\n",
    "'age' : 21, 'pay' : 40000}\n",
    "Jagdish = {'key' : 'Jagdish', 'name' : 'Jagdish Pathak',\n",
    "'age' : 50, 'pay' : 50000}\n",
    " \n",
    "# database\n",
    "db = {}\n",
    "db['Omkar'] = Omkar\n",
    "db['Jagdish'] = Jagdish\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.pickle', 'wb') as file:\n",
    "    pickle.dump(db, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Omkar': {'key': 'Omkar', 'name': 'Omkar Pathak', 'age': 21, 'pay': 40000},\n",
       " 'Jagdish': {'key': 'Jagdish',\n",
       "  'name': 'Jagdish Pathak',\n",
       "  'age': 50,\n",
       "  'pay': 50000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('db.pickle', 'rb') as file:\n",
    "    my_db = pickle.load(file)\n",
    "\n",
    "my_db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
