{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprendre MapReduce**\n",
    "\n",
    "## **Map**\n",
    "\n",
    "```map``` prend en argument une fonction et une collection et retourne une collection. La fonction étant appliquée sur chaque élément de la collection.\n",
    "\n",
    "**Exo1:** Utiliser la fonction ```map``` pour multiplier par 2 les éléments d'une liste. Faire une version en définissant une fonction et une seconde version en utilisant une fonction anonyme ```lambda```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 10, 14]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,5,7]\n",
    "\n",
    "b = map(lambda x : x * 2, a)\n",
    "list(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo2:** Créer une liste de 1000 entiers aléatoires. À l'aide de la fonction `map` retourner une collection qui contient `True` si le nombre était pair et `False` sinon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43603 52571 51354 16311 47282 96796 89059 27850 20111 39560]\n",
      "[False, False, True, False, True, True, False, True, False, True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = np.random.randint(10**5, size=10) #size=1000\n",
    "print(l)\n",
    "print(list(map(lambda x: x%2 == 0, l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pour faire simple, la seule différence entre le ```map``` de python et celui de spark c'est que le ```map``` de ce dernier découpe le calul sur plusieurs machines pour paralléliser le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce**\n",
    "\n",
    "La fonction ```reduce``` prend en entrée une collection et retourne une réduction de celle ci en lui appliquant une fonction d'agrégation itérative, c'est-à-dire, une fonction qui lit les valeurs de la liste de gauche à droite et ne renvoie qu'une seule valeur agrégée.  \n",
    "La fonction d'agrégation doit donc prendre 2 arguments et ne renvoyer qu'une seule valeur.\n",
    "\n",
    "Par exemple, ```reduce``` permet de calculer la somme des éléments d'une liste, ce qu'on va faire (enfin vous allez faire) de suite.\n",
    "\n",
    "**Exo3:** calculer la somme de la liste ```a``` :\n",
    ">1. en utilisant une boucle ```for```\n",
    ">2. en utilisant la fonction ```reduce``` du module ```functools```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = 0\n",
    "for x in a:\n",
    "    tot += x\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "tot = reduce(lambda x,y: x+y, a)\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo4:** générer une liste de 20 entiers entre 0 et 1000 et calculer le maximum de cette liste à l'aide de la fonction ```reduce```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879 158 787  92  53 698 987 707 120 266 953  55 506  61 990   1   0 767\n",
      " 461 259]\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "l = np.random.randint(10**3, size=20)\n",
    "print(l)\n",
    "print(reduce(lambda x,y : x if x>y else y, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo5:** importer la fonction ```accumulate``` du module ```itertools```, comprendre comment elle marche, la tester et la comparer avec ```reduce``` sur les 2 exemples précédents (somme et maximum d'une liste). Quelles sont les différences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39  79   0 512 583 536 829 637 703 494 386 386 461 919 513 829 136  81\n",
      " 325 338]\n",
      "[39, 118, 118, 630, 1213, 1749, 2578, 3215, 3918, 4412, 4798, 5184, 5645, 6564, 7077, 7906, 8042, 8123, 8448, 8786]\n",
      "[39, 79, 79, 512, 583, 583, 829, 829, 829, 829, 829, 829, 829, 919, 919, 919, 919, 919, 919, 919]\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "l = np.random.randint(10**3, size=20)\n",
    "print(l)\n",
    "print(list(accumulate(l, lambda x,y : x+y)))\n",
    "print(list(accumulate(l, lambda x,y : x if x>y else y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comme pour la fonction ```map``` la seule différence entre le ```reduce``` de python et celui de spark c'est que celui de spark découpe en plusieurs morceaux et parallélise le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Petit bonus : Filter**\n",
    "\n",
    "\n",
    "**Exo6**: créer une liste avec les valeurs suivantes : [-1, 3, 2, -1, 6, 8] puis utiliser la fonction ```filter``` pour récupérer uniquement les valeurs positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 6, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-1, 3, 2, -1, 6, 8]\n",
    "list(filter(lambda x: x>0, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Map et Reduce**\n",
    "\n",
    "On considère le mega big dataset suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"ceci n'est pas du big data\", 'Bonjour voilà du texte',\n",
    "     \"il est en retard tous les jours\", \"une bonne auberge\", \"elle est en Grèce\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo7:** utiliser la fonction ```map``` pour séparer chaque phrase en en mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ceci', \"n'est\", 'pas', 'du', 'big', 'data'],\n",
       " ['Bonjour', 'voilà', 'du', 'texte'],\n",
       " ['il', 'est', 'en', 'retard', 'tous', 'les', 'jours'],\n",
       " ['une', 'bonne', 'auberge'],\n",
       " ['elle', 'est', 'en', 'Grèce']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sep(ph):\n",
    "    return ph.split()\n",
    "\n",
    "#list(map(sep, a))\n",
    "list(map(lambda ph: ph.split(), a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo8:** à l'aide de ```map``` et/ou ```reduce``` renvoyer le nombre total de mots dans ```a```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped = map(lambda ph : len(ph.split()), a)\n",
    "reduce(lambda x,y : x+y, mapped)\n",
    "#reduce(lambda x,y : x+y, map(lambda ph : len(ph.split()), a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WordCount : le \"hello world\" du MapReduce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo9:** on va illustrer le fonctionnement de MapReduce pour compter le nombre d'occurence de chaque mot dans la variable ```text``` définie ci-dessous. Il faut donc éxecuter les 4 étapes suivantes (le preprocessing étant un petit supplément) :\n",
    ">1. SPLIT: découpage du texte en 4 sous-parties\n",
    ">2. petite étape de preprocessing avec :\n",
    ">>- suppression de la ponctuation,\n",
    ">>- passage en minuscules\n",
    ">>- suppression des mots de 1, 2 ou 3 lettres\n",
    ">3. MAP: avec la fonction ```map``` renvoyer une liste de (clé, valeur) : ici clé=mot et valeur=occurence=1\n",
    ">4. SHUFFLE (& SORT): regroupement des résultats : on doit avoir pour chaque clé le couple (clé, [val, val, val,...]) : ici (mot, [1,1,1,...])\n",
    ">5. REDUCE: sommer les occurences uniques de chaque mot pour obtenir le nombre d'occurrences totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Si vous voulez mon avis concernant la morosité conjoncturelle, \\\n",
    "je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, \\\n",
    "avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut \\\n",
    "pas s'interdire de se remémorer précisément les organisations matricielles \\\n",
    "opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de \\\n",
    "l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, \\\n",
    "même si ce n'est pas facile. Vu la dualité de la situation conjoncturelle, il ne \\\n",
    "faut pas négliger de gérer certaines synergies optimales, parce que nous le valons \\\n",
    "bien. Nonobstant la dualité de la situation observée, je n'exclus pas d'inventorier \\\n",
    "la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon \\\n",
    "avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la \\\n",
    "globalité des améliorations pertinentes, très attentivement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Si vous voulez mon avis concernant la morosité conjoncturelle, je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut pas\",\n",
       " \"s'interdire de se remémorer précisément les organisations matricielles opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, même si ce n'est\",\n",
       " \"pas facile. Vu la dualité de la situation conjoncturelle, il ne faut pas négliger de gérer certaines synergies optimales, parce que nous le valons bien. Nonobstant la dualité de la situation observée, je n'exclus\",\n",
       " \"pas d'inventorier la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la globalité des améliorations pertinentes, très attentivement.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPLIT\n",
    "mots = text.split()\n",
    "cuts = np.linspace(0, len(mots), 5, dtype=int)\n",
    "gp_mots = [mots[cuts[i]:cuts[i+1]] for i in range(4)]\n",
    "text_split = [\" \".join(gp_mots[i]) for i in range(4)]\n",
    "text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vous voulez avis concernant morosité conjoncturelle exclus réorganiser simultanéité hypothèses réalisables avec toute prudence requise égard fragilité actuelle faut'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PREPROCESSING\n",
    "import string\n",
    "\n",
    "def preprocess_text(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"'\", \" \")\n",
    "    s = s.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    gros_mots = filter(lambda x: len(x)>3, s.split())\n",
    "    return \" \".join(gros_mots)\n",
    "\n",
    "preprocess_text(text_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vous voulez avis concernant morosité conjoncturelle exclus réorganiser simultanéité hypothèses réalisables avec toute prudence requise égard fragilité actuelle faut'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text2(s):\n",
    "    return \" \".join(re.findall(r\"\\b\\w{4,}\\b\", s.lower()))\n",
    "\n",
    "preprocess_text2(text_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('vous', 1),\n",
       "  ('voulez', 1),\n",
       "  ('avis', 1),\n",
       "  ('concernant', 1),\n",
       "  ('morosité', 1),\n",
       "  ('conjoncturelle', 1),\n",
       "  ('exclus', 1),\n",
       "  ('réorganiser', 1),\n",
       "  ('simultanéité', 1),\n",
       "  ('hypothèses', 1),\n",
       "  ('réalisables', 1),\n",
       "  ('avec', 1),\n",
       "  ('toute', 1),\n",
       "  ('prudence', 1),\n",
       "  ('requise', 1),\n",
       "  ('égard', 1),\n",
       "  ('fragilité', 1),\n",
       "  ('actuelle', 1),\n",
       "  ('faut', 1)],\n",
       " [('interdire', 1),\n",
       "  ('remémorer', 1),\n",
       "  ('précisément', 1),\n",
       "  ('organisations', 1),\n",
       "  ('matricielles', 1),\n",
       "  ('opportunes', 1),\n",
       "  ('avec', 1),\n",
       "  ('beaucoup', 1),\n",
       "  ('recul', 1),\n",
       "  ('afin', 1),\n",
       "  ('circonvenir', 1),\n",
       "  ('cette', 1),\n",
       "  ('inflexion', 1),\n",
       "  ('époque', 1),\n",
       "  ('actuelle', 1),\n",
       "  ('recommande', 1),\n",
       "  ('essayer', 1),\n",
       "  ('somme', 1),\n",
       "  ('stratégies', 1),\n",
       "  ('envisageables', 1),\n",
       "  ('même', 1)],\n",
       " [('facile', 1),\n",
       "  ('dualité', 1),\n",
       "  ('situation', 1),\n",
       "  ('conjoncturelle', 1),\n",
       "  ('faut', 1),\n",
       "  ('négliger', 1),\n",
       "  ('gérer', 1),\n",
       "  ('certaines', 1),\n",
       "  ('synergies', 1),\n",
       "  ('optimales', 1),\n",
       "  ('parce', 1),\n",
       "  ('nous', 1),\n",
       "  ('valons', 1),\n",
       "  ('bien', 1),\n",
       "  ('nonobstant', 1),\n",
       "  ('dualité', 1),\n",
       "  ('situation', 1),\n",
       "  ('observée', 1),\n",
       "  ('exclus', 1)],\n",
       " [('inventorier', 1),\n",
       "  ('somme', 1),\n",
       "  ('modalités', 1),\n",
       "  ('réalisables', 1),\n",
       "  ('parce', 1),\n",
       "  ('temps', 1),\n",
       "  ('agir', 1),\n",
       "  ('vous', 1),\n",
       "  ('voulez', 1),\n",
       "  ('avis', 1),\n",
       "  ('concernant', 1),\n",
       "  ('baisse', 1),\n",
       "  ('confiance', 1),\n",
       "  ('présente', 1),\n",
       "  ('exclus', 1),\n",
       "  ('inventorier', 1),\n",
       "  ('globalité', 1),\n",
       "  ('améliorations', 1),\n",
       "  ('pertinentes', 1),\n",
       "  ('très', 1),\n",
       "  ('attentivement', 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def mapper(s):\n",
    "    return [(mot, 1) for mot in preprocess_text(s).split()]\n",
    "\n",
    "mapped = list(map(mapper, text_split))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actuelle', [1, 1]),\n",
       " ('afin', [1]),\n",
       " ('agir', [1]),\n",
       " ('améliorations', [1]),\n",
       " ('attentivement', [1]),\n",
       " ('avec', [1, 1]),\n",
       " ('avis', [1, 1]),\n",
       " ('baisse', [1]),\n",
       " ('beaucoup', [1]),\n",
       " ('bien', [1]),\n",
       " ('certaines', [1]),\n",
       " ('cette', [1]),\n",
       " ('circonvenir', [1]),\n",
       " ('concernant', [1, 1]),\n",
       " ('confiance', [1]),\n",
       " ('conjoncturelle', [1, 1]),\n",
       " ('dualité', [1, 1]),\n",
       " ('envisageables', [1]),\n",
       " ('essayer', [1]),\n",
       " ('exclus', [1, 1, 1]),\n",
       " ('facile', [1]),\n",
       " ('faut', [1, 1]),\n",
       " ('fragilité', [1]),\n",
       " ('globalité', [1]),\n",
       " ('gérer', [1]),\n",
       " ('hypothèses', [1]),\n",
       " ('inflexion', [1]),\n",
       " ('interdire', [1]),\n",
       " ('inventorier', [1, 1]),\n",
       " ('matricielles', [1]),\n",
       " ('modalités', [1]),\n",
       " ('morosité', [1]),\n",
       " ('même', [1]),\n",
       " ('nonobstant', [1]),\n",
       " ('nous', [1]),\n",
       " ('négliger', [1]),\n",
       " ('observée', [1]),\n",
       " ('opportunes', [1]),\n",
       " ('optimales', [1]),\n",
       " ('organisations', [1]),\n",
       " ('parce', [1, 1]),\n",
       " ('pertinentes', [1]),\n",
       " ('prudence', [1]),\n",
       " ('précisément', [1]),\n",
       " ('présente', [1]),\n",
       " ('recommande', [1]),\n",
       " ('recul', [1]),\n",
       " ('remémorer', [1]),\n",
       " ('requise', [1]),\n",
       " ('réalisables', [1, 1]),\n",
       " ('réorganiser', [1]),\n",
       " ('simultanéité', [1]),\n",
       " ('situation', [1, 1]),\n",
       " ('somme', [1, 1]),\n",
       " ('stratégies', [1]),\n",
       " ('synergies', [1]),\n",
       " ('temps', [1]),\n",
       " ('toute', [1]),\n",
       " ('très', [1]),\n",
       " ('valons', [1]),\n",
       " ('voulez', [1, 1]),\n",
       " ('vous', [1, 1]),\n",
       " ('égard', [1]),\n",
       " ('époque', [1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHUFFLE & SORT\n",
    "liste = [couple for subset in mapped for couple in subset]\n",
    "liste.sort()\n",
    "\n",
    "prev_wd = None\n",
    "wd_occur = list()\n",
    "shuffled_sorted = list()\n",
    "\n",
    "for k, v in liste:\n",
    "    if k != prev_wd:\n",
    "        if prev_wd != None:\n",
    "            shuffled_sorted.append((prev_wd, wd_occur))\n",
    "        prev_wd, wd_occur = k, [v]\n",
    "    else:\n",
    "        wd_occur.append(v)\n",
    "\n",
    "shuffled_sorted.append((prev_wd, wd_occur))\n",
    "shuffled_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHUFFLE & SORT\n",
    "liste = [couple for subset in mapped for couple in subset]\n",
    "liste.sort()\n",
    "\n",
    "from collections import defaultdict\n",
    "dico = defaultdict(list)\n",
    "\n",
    "for k,v in liste :\n",
    "    dico[k].append(v)\n",
    "\n",
    "shuffled_sorted = list(dico.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actuelle', 2),\n",
       " ('afin', 1),\n",
       " ('agir', 1),\n",
       " ('améliorations', 1),\n",
       " ('attentivement', 1),\n",
       " ('avec', 2),\n",
       " ('avis', 2),\n",
       " ('baisse', 1),\n",
       " ('beaucoup', 1),\n",
       " ('bien', 1),\n",
       " ('certaines', 1),\n",
       " ('cette', 1),\n",
       " ('circonvenir', 1),\n",
       " ('concernant', 2),\n",
       " ('confiance', 1),\n",
       " ('conjoncturelle', 2),\n",
       " ('dualité', 2),\n",
       " ('envisageables', 1),\n",
       " ('essayer', 1),\n",
       " ('exclus', 3),\n",
       " ('facile', 1),\n",
       " ('faut', 2),\n",
       " ('fragilité', 1),\n",
       " ('globalité', 1),\n",
       " ('gérer', 1),\n",
       " ('hypothèses', 1),\n",
       " ('inflexion', 1),\n",
       " ('interdire', 1),\n",
       " ('inventorier', 2),\n",
       " ('matricielles', 1),\n",
       " ('modalités', 1),\n",
       " ('morosité', 1),\n",
       " ('même', 1),\n",
       " ('nonobstant', 1),\n",
       " ('nous', 1),\n",
       " ('négliger', 1),\n",
       " ('observée', 1),\n",
       " ('opportunes', 1),\n",
       " ('optimales', 1),\n",
       " ('organisations', 1),\n",
       " ('parce', 2),\n",
       " ('pertinentes', 1),\n",
       " ('prudence', 1),\n",
       " ('précisément', 1),\n",
       " ('présente', 1),\n",
       " ('recommande', 1),\n",
       " ('recul', 1),\n",
       " ('remémorer', 1),\n",
       " ('requise', 1),\n",
       " ('réalisables', 2),\n",
       " ('réorganiser', 1),\n",
       " ('simultanéité', 1),\n",
       " ('situation', 2),\n",
       " ('somme', 2),\n",
       " ('stratégies', 1),\n",
       " ('synergies', 1),\n",
       " ('temps', 1),\n",
       " ('toute', 1),\n",
       " ('très', 1),\n",
       " ('valons', 1),\n",
       " ('voulez', 2),\n",
       " ('vous', 2),\n",
       " ('égard', 1),\n",
       " ('époque', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE\n",
    "def reducer(key, values):\n",
    "    return (key, sum(values))\n",
    "\n",
    "reduced = list(map(lambda couple: reducer(couple[0], couple[1]), shuffled_sorted))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pour : finir moyenne de liste et temps d'éxecution**\n",
    "\n",
    "**Exo10:** à l'aide des fonctions ```map``` et ```reduce```, on va calculer la moyenne des éléments d'une liste. Et sans utiliser ```len()```...\n",
    ">1. créer une liste d'entiers aléatoires de taille 10^7\n",
    ">2. utiliser ```map``` et ```reduce``` pour calculer la moyenne sur cette liste\n",
    ">3. utiliser ```%%time``` pour mesurer le temps d'éxecution de ce calcul\n",
    ">4. découper la liste en 5 sous-listes de tailles égales\n",
    ">5. importer la fonction ```Pool``` de la libraire ```multiprocessing``` et l'utiliser pour paralléliser les calculs sur chaque sous-liste. L'idée est de définir par exemple une fonction MapReduce_average qui reprend votre méthode utilisée pour le calcul de la moyenne et utiliser pool.map(MapReduce_average, liste_splitée)\n",
    ">6. regarder avec %%time les différences de temps d'éxecution des 2 méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  np.random.randint(1000, size=10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.31 s, sys: 3.55 ms, total: 3.32 s\n",
      "Wall time: 3.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499.5265801"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a_mapped = map(lambda val : (val, 1), a)\n",
    "a_reduced = reduce(lambda x,y : (x[0]+y[0], x[1]+y[1]), a_mapped)\n",
    "a_reduced[0]/a_reduced[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([718, 511, 109, ..., 409, 709, 305]),\n",
       " array([718,  43,  36, ..., 843, 650,  83]),\n",
       " array([344,  90, 785, ..., 536, 188, 433]),\n",
       " array([297, 642, 384, ..., 477, 304, 945]),\n",
       " array([672, 808, 260, ..., 693, 658, 838]),\n",
       " array([ 69, 752, 693, ..., 564, 210,  71]),\n",
       " array([287, 852, 212, ..., 282, 611, 123]),\n",
       " array([159, 919, 216, ..., 693, 153, 399])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cores = 8\n",
    "cuts = np.linspace(0, 10**7, nb_cores+1, dtype=int)\n",
    "a_split = [a[cuts[k]:cuts[k+1]] for k in range(nb_cores)]\n",
    "a_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool\n",
    "pool = Pool(nb_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr_avg(l):\n",
    "    mapped = map(lambda i : (i,1), l)\n",
    "    return(reduce(lambda x,y : (x[0]+y[0], x[1]+y[1]), mapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 ms, sys: 36.7 ms, total: 89.4 ms\n",
      "Wall time: 1.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499.5265801"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mapped = pool.map(mr_avg, a_split)\n",
    "reduced = reduce(lambda x,y : (x[0]+y[0], x[1]+y[1]), mapped)\n",
    "a_reduced[0]/a_reduced[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supplément**\n",
    "\n",
    "**Exo11:** Calculer en utilisant le paradigme MapReduce le produit d'une matrice M avec un vecteur V.  \n",
    "Ça peut paraître inutile mais cette opération est derrière l'algorithme du PageRank de Google, c'est d'ailleurs en partie pour ce calcul que MapReduce a été conçu. Dans ce cas, la dimension du problème est le nombre de pages web indexées, soit clairement un problème de Big Data.  \n",
    "Par ailleurs, on l'a vu dans la régression linéaire notamment mais pas uniquement, ce produit $matrice*vecteur$ est omniprésent dans les problèmes d'optimisation aussi.\n",
    ">*Quelques indications:*\n",
    "\n",
    ">0. commencer par vous remettre dans le bain en revoyant comment on calcul un produit matriciel et plus exactement un produit $matrice*vecteur$\n",
    ">1. générer une matrice aléatoire $M$ de taille (5,6) par exemple et un vecteur de taille 6\n",
    ">2. transformer votre matrice $M$ en une liste de triplet $(i,j,m_{ij})$\n",
    ">3. étape map : on peut choisir comme clé le numéro de ligne et l'étape map consistera donc à passer du triplet $(i,j,m_{ij})$ au couple $(i,m_{ij}*v_j)$\n",
    ">4. étape shuffle&sort : il faut regrouper les couples (clé, valeur) en (clé, liste_de_valeurs), la clé étant ici l'indice de ligne $i$\n",
    ">5. étape réduce : agréger les résultats en les sommant\n",
    "\n",
    "*Pour aller plus loin:* cette solution marche convenablement lorsque chaque noeud a la capacité de stocker $V$ localement mais que faire si $V$ est trop grand ? Vous pouvez mettre en pratique votre solution avec les mêmes $M$ et $V$ que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 2 2 7 9 5]\n",
      " [5 2 4 0 6 2]\n",
      " [0 6 0 5 1 5]\n",
      " [7 5 3 7 1 9]\n",
      " [8 1 7 0 2 8]] [1 9 8 1 6 7]\n"
     ]
    }
   ],
   "source": [
    "# génération matrice\n",
    "M = np.random.randint(10, size=(5,6))\n",
    "V =  np.random.randint(10, size=6)\n",
    "print(M, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 7),\n",
       " (0, 1, 2),\n",
       " (0, 2, 2),\n",
       " (0, 3, 7),\n",
       " (0, 4, 9),\n",
       " (0, 5, 5),\n",
       " (1, 0, 5),\n",
       " (1, 1, 2),\n",
       " (1, 2, 4),\n",
       " (1, 3, 0),\n",
       " (1, 4, 6),\n",
       " (1, 5, 2),\n",
       " (2, 0, 0),\n",
       " (2, 1, 6),\n",
       " (2, 2, 0),\n",
       " (2, 3, 5),\n",
       " (2, 4, 1),\n",
       " (2, 5, 5),\n",
       " (3, 0, 7),\n",
       " (3, 1, 5),\n",
       " (3, 2, 3),\n",
       " (3, 3, 7),\n",
       " (3, 4, 1),\n",
       " (3, 5, 9),\n",
       " (4, 0, 8),\n",
       " (4, 1, 1),\n",
       " (4, 2, 7),\n",
       " (4, 3, 0),\n",
       " (4, 4, 2),\n",
       " (4, 5, 8)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformation en liste de triplets\n",
    "M_liste = [(i,j,M[i,j]) for i in range(M.shape[0]) for j in range(M.shape[1])]\n",
    "M_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 7),\n",
       " (0, 18),\n",
       " (0, 16),\n",
       " (0, 7),\n",
       " (0, 54),\n",
       " (0, 35),\n",
       " (1, 5),\n",
       " (1, 18),\n",
       " (1, 32),\n",
       " (1, 0),\n",
       " (1, 36),\n",
       " (1, 14),\n",
       " (2, 0),\n",
       " (2, 54),\n",
       " (2, 0),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 35),\n",
       " (3, 7),\n",
       " (3, 45),\n",
       " (3, 24),\n",
       " (3, 7),\n",
       " (3, 6),\n",
       " (3, 63),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (4, 56),\n",
       " (4, 0),\n",
       " (4, 12),\n",
       " (4, 56)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def prod(triplet):\n",
    "    i,j,Mij = triplet\n",
    "    return i, Mij*V[j]\n",
    "\n",
    "mapped = list(map(prod, M_liste))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [7, 18, 16, 7, 54, 35]),\n",
       " (1, [5, 18, 32, 0, 36, 14]),\n",
       " (2, [0, 54, 0, 5, 6, 35]),\n",
       " (3, [7, 45, 24, 7, 6, 63]),\n",
       " (4, [8, 9, 56, 0, 12, 56])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHUFFLE AND SORT\n",
    "from collections import defaultdict\n",
    "dico = defaultdict(list)\n",
    "for k,v in mapped :\n",
    "    dico[k].append(v)\n",
    "shuffled = list(dico.items())\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 137), (1, 105), (2, 100), (3, 152), (4, 141)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE\n",
    "def reducer(key, values):\n",
    "    return (key, sum(values))\n",
    "\n",
    "reduced = list(map(lambda tup: reducer(tup[0], tup[1]), shuffled))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137, 105, 100, 152, 141]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si on veut représenter le vecteur sous forme de liste:\n",
    "[x[1] for x in reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pour aller plus loin:* cas où $V$ ne peut pas être stocké entièrement dans les noeuds\n",
    "\n",
    "La solution est assez triviale en théorie: puisque $V$ ne rentre pas dans un noeud, il faut le découper de sorte que chaque noeud s'occupe d'une partie du calcul.  \n",
    "**Attention** derrière la simplicité de cette solution, il y a toutefois une petite subtilité. En effet, puisqu'on découpe $V$, il faut aussi découper $M$ de manière cohérente.\n",
    "\n",
    "Dans notre exemple $M$ est de taille (5,6) et $V$ et de taille 6 c'est-à-dire en fait de taille (6,1).  \n",
    "On découpe $V$ horizontalement en trois vecteurs de taille (2,1).  \n",
    "Il faut donc pour pouvoir faire le produit découper $M$ \"verticalement\" en trois matrices de tailles (5,2).\n",
    "Ensuite on aura plus qu'à regrouper les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 2 2 7 9 5]\n",
      " [5 2 4 0 6 2]\n",
      " [0 6 0 5 1 5]\n",
      " [7 5 3 7 1 9]\n",
      " [8 1 7 0 2 8]]\n",
      "[1 9 8 1 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(M)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[7, 2],\n",
       "         [5, 2],\n",
       "         [0, 6],\n",
       "         [7, 5],\n",
       "         [8, 1]]),\n",
       "  array([1, 9])),\n",
       " (array([[2, 7],\n",
       "         [4, 0],\n",
       "         [0, 5],\n",
       "         [3, 7],\n",
       "         [7, 0]]),\n",
       "  array([8, 1])),\n",
       " (array([[9, 5],\n",
       "         [6, 2],\n",
       "         [1, 5],\n",
       "         [1, 9],\n",
       "         [2, 8]]),\n",
       "  array([6, 7]))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_splitted = [M[:,0:2], M[:,2:4],  M[:,4:6]]\n",
    "V_splitted = [V[0:2], V[2:4], V[4:6]]\n",
    "\n",
    "#on peut recréer un couple sous-matrice/sous-vecteur qui correspond à l'information stockée dans chaque noeud du cluster\n",
    "MV = [(M_splitted[k], V_splitted[k]) for k in range(3)]\n",
    "MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(0, 0, 7),\n",
       "   (0, 1, 2),\n",
       "   (1, 0, 5),\n",
       "   (1, 1, 2),\n",
       "   (2, 0, 0),\n",
       "   (2, 1, 6),\n",
       "   (3, 0, 7),\n",
       "   (3, 1, 5),\n",
       "   (4, 0, 8),\n",
       "   (4, 1, 1)],\n",
       "  [1, 9]),\n",
       " ([(0, 0, 2),\n",
       "   (0, 1, 7),\n",
       "   (1, 0, 4),\n",
       "   (1, 1, 0),\n",
       "   (2, 0, 0),\n",
       "   (2, 1, 5),\n",
       "   (3, 0, 3),\n",
       "   (3, 1, 7),\n",
       "   (4, 0, 7),\n",
       "   (4, 1, 0)],\n",
       "  [8, 1]),\n",
       " ([(0, 0, 9),\n",
       "   (0, 1, 5),\n",
       "   (1, 0, 6),\n",
       "   (1, 1, 2),\n",
       "   (2, 0, 1),\n",
       "   (2, 1, 5),\n",
       "   (3, 0, 1),\n",
       "   (3, 1, 9),\n",
       "   (4, 0, 2),\n",
       "   (4, 1, 8)],\n",
       "  [6, 7])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformation en liste de triplets\n",
    "def triplets(block):\n",
    "    M = block[0]\n",
    "    V = block[1]\n",
    "    return [(i,j,M[i,j]) for i in range(M.shape[0]) for j in range(M.shape[1])], list(V)\n",
    "\n",
    "MV_triplets = list(map(triplets, MV))\n",
    "MV_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 7),\n",
       "  (0, 18),\n",
       "  (1, 5),\n",
       "  (1, 18),\n",
       "  (2, 0),\n",
       "  (2, 54),\n",
       "  (3, 7),\n",
       "  (3, 45),\n",
       "  (4, 8),\n",
       "  (4, 9)],\n",
       " [(0, 16),\n",
       "  (0, 7),\n",
       "  (1, 32),\n",
       "  (1, 0),\n",
       "  (2, 0),\n",
       "  (2, 5),\n",
       "  (3, 24),\n",
       "  (3, 7),\n",
       "  (4, 56),\n",
       "  (4, 0)],\n",
       " [(0, 54),\n",
       "  (0, 35),\n",
       "  (1, 36),\n",
       "  (1, 14),\n",
       "  (2, 6),\n",
       "  (2, 35),\n",
       "  (3, 6),\n",
       "  (3, 63),\n",
       "  (4, 12),\n",
       "  (4, 56)]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def mapper(block):\n",
    "    M = block[0]\n",
    "    V = block[1]\n",
    "    return [(triplet[0], triplet[2]*V[triplet[1]]) for triplet in M]\n",
    "    \n",
    "mapped = list(map(mapper, MV_triplets))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, [7, 18]), (1, [5, 18]), (2, [0, 54]), (3, [7, 45]), (4, [8, 9])],\n",
       " [(0, [16, 7]), (1, [32, 0]), (2, [0, 5]), (3, [24, 7]), (4, [56, 0])],\n",
       " [(0, [54, 35]), (1, [36, 14]), (2, [6, 35]), (3, [6, 63]), (4, [12, 56])]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHUFFLE AND SORT\n",
    "def shfld(block):\n",
    "    dico = defaultdict(list)\n",
    "    list(map(lambda tup : dico[tup[0]].append(tup[1]), block))\n",
    "    return list(dico.items())\n",
    "\n",
    "shuffled = list(map(shfld, mapped))\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 25), (1, 23), (2, 54), (3, 52), (4, 17)],\n",
       " [(0, 23), (1, 32), (2, 5), (3, 31), (4, 56)],\n",
       " [(0, 89), (1, 50), (2, 41), (3, 69), (4, 68)]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE\n",
    "def reducer(block):\n",
    "    return list(map(lambda tup: (tup[0], sum(tup[1])), block))\n",
    "\n",
    "reduced = list(map(reducer, shuffled))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 137), (1, 105), (2, 100), (3, 152), (4, 141)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On réitère SHUFFLE AND SORT + REDUCE sur la liste qui regroupe les résultats de chaque noeud\n",
    "liste = [item for sublist in reduced for item in sublist]\n",
    "reducer(shfld(liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[137, 105, 100, 152, 141]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pour avoir le vecteur final\n",
    "[c[1] for c in reducer(shfld(liste))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "addda3f63a324b7a38ec870d79a82ab21d33100c2675b6c03c06d4beeb089079"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
