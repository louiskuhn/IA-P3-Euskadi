{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprendre MapReduce**\n",
    "\n",
    "## **Map**\n",
    "\n",
    "```map``` prend en argument une fonction et une collection et retourne une collection. La fonction étant appliquée sur chaque élément de la collection.\n",
    "\n",
    "**Exo1:** Utiliser la fonction ```map``` pour multiplier par 2 les éléments d'une liste. Faire une version en définissant une fonction et une seconde version en utilisant une fonction anonyme ```lambda```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo2:** Créer une liste de 1000 entiers aléatoires. À l'aide de la fonction `map` retourner une collection qui contient `True` si le nombre était pair et `False` sinon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pour faire simple, la seule différence entre le ```map``` de python et celui de spark c'est que le ```map``` de ce dernier découpe le calul sur plusieurs machines pour paralléliser le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce**\n",
    "\n",
    "La fonction ```reduce``` prend en entrée une collection et retourne une réduction de celle ci en lui appliquant une fonction d'agrégation itérative, c'est-à-dire, une fonction qui lit les valeurs de la liste de gauche à droite et ne renvoie qu'une seule valeur agrégée.  \n",
    "La fonction d'agrégation doit donc prendre 2 arguments et ne renvoyer qu'une seule valeur.\n",
    "\n",
    "Par exemple, ```reduce``` permet de calculer la somme des éléments d'une liste, ce qu'on va faire (enfin vous allez faire) de suite.\n",
    "\n",
    "**Exo3:** calculer la somme de la liste ```a``` :\n",
    ">1. en utilisant une boucle ```for```\n",
    ">2. en utilisant la fonction ```reduce``` du module ```functools```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo4:** générer une liste de 20 entiers entre 0 et 1000 et calculer le maximum de cette liste à l'aide de la fonction ```reduce```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo5:** importer la fonction ```accumulate``` du module ```itertools```, comprendre comment elle marche, la tester et la comparer avec ```reduce``` sur les 2 exemples précédents (somme et maximum d'une liste). Quelles sont les différences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comme pour la fonction ```map``` la seule différence entre le ```reduce``` de python et celui de spark c'est que celui de spark découpe en plusieurs morceaux et parallélise le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Petit bonus : Filter**\n",
    "\n",
    "\n",
    "**Exo6**: créer une liste avec les valeurs suivantes : [-1, 3, 2, -1, 6, 8] puis utiliser la fonction ```filter``` pour récupérer uniquement les valeurs positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Map et Reduce**\n",
    "\n",
    "On considère le mega big dataset suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"ceci n'est pas du big data\", 'Bonjour voilà du texte',\n",
    "     \"il est en retard tous les jours\", \"une bonne auberge\", \"elle est en Grèce\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo7:** utiliser la fonction ```map``` pour séparer chaque phrase en en mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo8:** à l'aide de ```map``` et/ou ```reduce``` renvoyer le nombre total de mots dans ```a```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WordCount : le \"hello world\" du MapReduce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo9:** on va illustrer le fonctionnement de MapReduce pour compter le nombre d'occurence de chaque mot dans la variable ```text``` définie ci-dessous. Il faut donc éxecuter les 4 étapes suivantes (le preprocessing étant un petit supplément) :\n",
    ">1. SPLIT: découpage du texte en 4 sous-parties\n",
    ">2. petite étape de preprocessing avec :\n",
    ">>- suppression de la ponctuation,\n",
    ">>- passage en minuscules\n",
    ">>- suppression des mots de 1, 2 ou 3 lettres\n",
    ">3. MAP: avec la fonction ```map``` renvoyer une liste de (clé, valeur) : ici clé=mot et valeur=occurence=1\n",
    ">4. SHUFFLE (& SORT): regroupement des résultats : on doit avoir pour chaque clé le couple (clé, [val, val, val,...]) : ici (mot, [1,1,1,...])\n",
    ">5. REDUCE: sommer les occurences uniques de chaque mot pour obtenir le nombre d'occurrences totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Si vous voulez mon avis concernant la morosité conjoncturelle, \\\n",
    "je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, \\\n",
    "avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut \\\n",
    "pas s'interdire de se remémorer précisément les organisations matricielles \\\n",
    "opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de \\\n",
    "l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, \\\n",
    "même si ce n'est pas facile. Vu la dualité de la situation conjoncturelle, il ne \\\n",
    "faut pas négliger de gérer certaines synergies optimales, parce que nous le valons \\\n",
    "bien. Nonobstant la dualité de la situation observée, je n'exclus pas d'inventorier \\\n",
    "la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon \\\n",
    "avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la \\\n",
    "globalité des améliorations pertinentes, très attentivement.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pour : finir moyenne de liste et temps d'éxecution**\n",
    "\n",
    "**Exo10:** à l'aide des fonctions ```map``` et ```reduce```, on va calculer la moyenne des éléments d'une liste. Et sans utiliser ```len()```...\n",
    ">1. créer une liste d'entiers aléatoires de taille 10^7\n",
    ">2. utiliser ```map``` et ```reduce``` pour caluler la moyenne sur cette liste\n",
    ">3. utiliser ```%%time``` pour mesurer le temps d'éxecution de ce calcul\n",
    ">4. découper la liste en 5 sous-listes de tailles égales\n",
    ">5. importer le module ```Pool``` de la libraire ```multiprocessing``` et l'utiliser pour paralléliser les calculs sur chaque sous-liste. L'idée est de définir par exemple une fonction MapReduce_average qui reprend votre méthode utilisée pour le calcul de la moyenne et utiliser pool.map(MapReduce_average, liste_splitée)\n",
    ">6. regarder avec %%time les différences de temps d'éxecution des 2 méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supplément**\n",
    "\n",
    "**Exo11:** Calculer en utilisant le paradigme MapReduce le produit d'une matrice M avec un vecteur V.  \n",
    "Ça peut paraître inutile mais cette opération est derrière l'algorithme du PageRank de Google, c'est d'ailleurs en partie pour ce calcul que MapReduce a été conçu. Dans ce cas, la dimension du problème est le nombre de pages web indexées, soit clairement un problème de Big Data.  \n",
    "Par ailleurs, on l'a vu dans la régression linéaire notamment mais pas uniquement, ce produit $matrice*vecteur$ est omniprésent dans les problèmes d'optimisation aussi.\n",
    ">*Quelques indications:*\n",
    "\n",
    ">0. commencer par vous remettre dans le bain en revoyant comment on calcul un produit matriciel et plus exactement un produit $matrice*vecteur$\n",
    ">1. générer une matrice aléatoire $M$ de taille (5,6) par exemple et un vecteur de taille 6\n",
    ">2. transformer votre matrice $M$ en une liste de triplet $(i,j,m_{ij})$\n",
    ">3. étape map : on peut choisir comme clé le numéro de ligne et l'étape map consistera donc à passer du triplet $(i,j,m_{ij})$ au couple $(i,m_{ij}*v_j)$\n",
    ">4. étape shuffle&sort : il faut regrouper les couples (clé, valeur) en (clé, liste_de_valeurs), la clé étant ici l'indice de ligne $i$\n",
    ">5. étape réduce : agréger les résultats en les sommant\n",
    "\n",
    "*Pour aller plus loin:* cette solution marche convenablement lorsque chaque noeud a la capacité de stocker $V$ localement mais que faire si $V$ est trop grand ? Vous pouvez mettre en pratique votre solution avec les mêmes $M$ et $V$ que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pour aller plus loin:* cas où $V$ ne peut pas être stocké entièrement dans les noeuds\n",
    "\n",
    "La solution est assez triviale en théorie: puisque $V$ ne rentre pas dans un noeud, il faut le découper de sorte que chaque noeud s'occupe d'une partie du calcul.  \n",
    "**Attention** derrière la simplicité de cette solution, il y a toutefois une petite subtilité. En effet, puisqu'on découpe $V$, il faut aussi découper $M$ de manière cohérente.\n",
    "\n",
    "Dans notre exemple $M$ est de taille (5,6) et $V$ et de taille 6 c'est-à-dire en fait de taille (6,1).  \n",
    "On découpe $V$ horizontalement en trois vecteurs de taille (2,1).  \n",
    "Il faut donc pour pouvoir faire le produit découper $M$ \"verticalement\" en trois matrices de tailles (5,2).\n",
    "Ensuite on aura plus qu'à regrouper les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n[GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "addda3f63a324b7a38ec870d79a82ab21d33100c2675b6c03c06d4beeb089079"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
